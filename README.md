# web-scraper

Download sites for archiving and or for learning how they were constructed!

I have been looking into reverse-engineering sites the last few years, with various tools like Webcrack, Madge, and ChatGPT (shame on me!) for reverse-engineering the symbols in the function definitions. Once you are able to see what the names of certain variables might have been, it is much easier to figure out how the logic of the app works, and to learn how they structured things.

### Background

Got help from GPT to get the initial boilerplate for this started. For me, getting started is the hardest part for new projects (understandably), so I tend to scaffold them out with GPT, outlining what the goals and limitations are for what the project should do. Then I can meander what it puts together into something more specific to what I know will work. My goal lately has been to make projects which will the void of things that I need in my own progression. It's not to solely learn every single exact thing and how to build it outright (that has been my goal for the longest time). So I'm okay with outside input like this to get started, because I want something usable quick, rather than getting stuck in the fine details, and not getting that thing built. I am still very much into learning new things intentionally. I have found the things I need to learn successfully as well too though. I seem to learn by example and comparison. If I can equate new skills to ones I am familiar with, the ability to compare and contrast them is invaluable to my learning. That's where I can start to make ideas of my own, which aren't as simple that something else might be able to come up with, like an AI prompt. I can come up with some wacky ideas for sure. Those are where I want my complete creative energy, not in making the tools to get to that point. For example, this project lines up with that perfectly. I want to learn how various websites are made, by breaking them apart and reverse-engineering their code. That is where my learning will be focused. I would need this tool to be able to do that though. So the longer this tool takes to make, the later it will be that I can learn from how some sites are made. So this project is more of a means to an end. A lot of it involves technology I am already familiar too, like Node, TypeScript, ESM, CommonJS, Puppeteer (that's the less familiar of those ones, hence why I need to get some help when using it).

I do see how this could actually be a great thing for me to work towards too though. If I were to be able to not need GPT to get started. If I could just have the skills to know how to do that stuff with my own reading and learning from docs and types. I have a hunch that GPT has a big one-up on me (and us as people) in general though. And that's okay! Still something I can work on though. It's always good to not need as many 'dependencies' I've found (in my own life).

### Goal of the project

I want to download all the contents of a PWA site. I want to get all things that it requires to run, like JS, images, HTML, CSS, all of those things. What's the easiest way to automate this? Right now, I am doing it with the Network tab in Chrome, manually downloading assets which were fetched over the lifetime of the app, as well as with the Ctrl+S functionality, then combining the results from these two to make the complete app runnable locally, just with my own copies of the files, solely over localhost. It should be able to run without any calls to the network, simply only using the cloned copies we downloaded.
